![ethics](/uploads/354d5736026b600895426474d45d9f07/ethics.png)

## Ethical aspects

AI ethics are the set of guiding principles that stakeholders (from engineers to government officials) use to ensure artificial intelligence technology is developed and used responsibly. This means taking a safe, secure, humane, and environmentally friendly approach to AI. A strong AI code of ethics can include avoiding bias, ensuring privacy of users and their data, and mitigating environmental risks.

# WHY ?

![WHY](/uploads/37b745c6a7d93f2e5bb39007acfe77ad/WHY.png)

Many of the pioneers behind the invention of Some technology and AI constantly questioned the “why” behind their work. They sought to understand the deeper purpose and implications of artificial intelligence and why we should create it, how it would impact society, and what ethical considerations it would bring. 

_Justin Rosenstein, former Google and Facebook engineer, 2017_ : **It is very common for humans to develop things with the best of intentions that have unintended, negative consequences.**

_James Williams, former Google employee, 2017_ : **This is the largest, most standardised and most centralised form of attention control in human history.**

_Tristan Harris, former Google employee, 2017_ : **Our choices are not as free as we think they are.**

_Stephen Hawking, BBC 2014_ : **The primitive forms of artificial intelligence we already have, have proved very useful. But I think the development of full artificial intelligence could spell the end of the human race.**

### WORLD ECONOMIC FORUM

**WEF’s top 9 ethical issues in artificial intelligence**

1. **Unemployment.** What happens after the end of jobs?
2. **Inequality.** How do we distribute the wealth created by machines?
3. **Humanity.** How do machines affect our behaviour and interaction?
4. **Artificial stupidity.** How can we guard against mistakes?
5. **Racist robots.** How do we eliminate AI bias?
6. **Security.** How do we keep AI safe from adversaries?
7. **Evil genies.** How do we protect against unintended consequences?
8.** Singularity.** How do we stay in control of a complex intelligent system?
9. **Robot rights.** How do we define the humane treatment of AI?

# ETHICS THEORY

Ethical theories of AI have been a focus for philosophers for hundreds of years because they address fundamental questions about morality, decision-making, and the role of technology in society. AI itself is a modern development, the underlying ethical issues, such as autonomy, responsibility, fairness, and the impact of human creations have been central to philosophical inquiry for centuries.

![a](/uploads/3c70dfceaee79a9479003a55c1e1081d/a.png)

#### Consequentialism

- Focuses on the consequences of our actions
- Asks the question: What action produces the best outcome
⇒ action + consequences > intention

#### Deontology

- The means must be justifiable on their own merits
- The morality of an action should be based on whether that action itself is right or wrong under a series of rules ⇒ “Moral Code”
- Asks the question: What is the right action, based on my moral code?
=> Intention + action > consequences

#### Virtue Ethics

- Focuses on the character of the agent
- Pursuit of virtues is essential to good character
- Become a good person, and the morally right actions will follow effortlessly
- Asks the question: What would a virtuous person do?

### PRIVACY AND SECURITY 

In Europe, the EU prioritise personal privacy by implementing regulations such as the General Data Protection Regulation (GDPR), which limits the use of AI that violates personal privacy.  AI systems, such as facial recognition, are closely examined to ensure compliance with strict data protection laws, and their use in public spaces is often limited to prevent mass surveillance.

In China AI is widely used for surveillance, with facial recognition systems deployed nationwide to observe and control actions. These systems are incorporated into programs such as the Social Credit System, which monitors and rates individual's behaviuors, influencing their access to services or opportunities.

![a1](/uploads/987d91c24185ac1ad11e7d633a92debf/a1.png)

The mix of corporate interests and varied regulations influences AI privacy. After the Capitol riots, a U.S. website used AI facial recognition to identify individuals in Parler videos, sparking ethical debates about privacy and consent. Despite the lack of overarching federal privacy laws in the U.S., specific regulations such as the California Consumer Privacy Act (CCPA) have been implemented by states like California to combat data misuse.

![a2](/uploads/6357e43b4c79366356e7afd48006f085/a2.png)


### Misinformation, transparency & bias

AI systems are facing more scrutiny due to their involvement in spreading misinformation, lack of transparency, and built-in biases. Algorithms, especially in social media platforms, have the potential to magnify incorrect information because they prioritise user engagement over factual correctness. Transparency is a challenge because many AI systems function as "black boxes," causing difficulties in understanding decision-making processes, leading to accountability concerns. Furthermore, biases in artificial intelligence frequently originate from training data that is not representative or flawed, resulting in unjust results in fields such as hiring, policing, or loan approvals. 

![a3](/uploads/e4fc9979c0105fc3d91cd562c665e1a5/a3.png)

![a4](/uploads/59602e504b75ffe93bd514d75f5477d1/a4.png)

### Sustainable AI

This topic focuses on reducing the environmental impact of AI technologies by optimising energy consumption and designing eco-friendly systems. Training large AI models requires significant computational power, often resulting in high carbon emissions.

From this topic i learnt that the cost of 1 Siri/Google Assistant command is 11g CO2

![Co2](/uploads/4247bda6c0437dd0484793cb4a1710b1/Co2.png)


Every time a voice command is analyzed by AI helpers such as Siri or Google Assistant, there is a computational expense. One query usually uses the same amount of energy as a small light bulb running briefly, adding to total carbon emissions.

![Sai](/uploads/92c46f2051659ce2f1627c9265d33f83/Sai.png)

As you can see in the photo above, a CO2 emission benchmarks, comparing various activities' of carbon footprints. It highlights that AI model training generates much higher emissions (626.2 thousand lbs) than activities like flying from New York City to San Francisco (2.0 thousand lbs per passenger), the average human yearly emissions (11.0 thousand lbs), and the lifetime emissions from U.S. car production and fuel use (126.0 thousand lbs). 